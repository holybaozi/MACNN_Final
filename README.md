# MACNN_Final
We investigate a novel end-to-end model based on deep learning named as Multi-scale Attention Convolutional Neural Network (MACNN) to solve the time series classification problem. We first apply the multi-scale convolution to capture different scales of information along the time axis by generating different scales of feature maps. Then an attention mechanism is proposed to enhance useful feature maps and suppress less useful ones by learning the importance of each feature map automatically.

## Before Start
To validate the effectiveness of MACNN, we propose two more models for comparison. One is the Single-scale Attention Convolutional Neural Network (SACNN) which has the same architecture with MACNN except for the multi convolutional layers. The other is the Multi-scale Convolutional Neural Network (MCNN) which differs from the architecture of MACNN by removing the attention block.

## MACNN_Validation
We carry out 3-fold cross-validation to confirm the final structure and hyperparameters.

Firstly, we fix the batch size, learning rate, reduction factor and training epochs to 16, 0.001, 16, and 1500 respectively as other researchers used in their study.We choose 
several datasets with different domains and lengths, including CinCECGTorso, Coffee, CricketX, FacesUCR, ItalyPower, and Mallat. Then we try different structures which consist 
of 1 to 6 sections on these datasets (the output section is not included). We apply 3-fold cross-validation on each chosen dataset to obtain the validation error of different 
structures. We determine the final structrue which achieves the lowest averaged validation error. Therefore, we choose the structure of 3 sections as the final structure of our research.

Secondly, we tune the hyperparameters by trying different hyperparameters combinations under the fixed structure. We choose the batch size, learning rate, reduction factor and 
training epoch from [4,8,16,32], [0.01,0.001,0.0001], [4,8,16,32], and [1000,1500,2000] respectively, and adopt 3-fold cross-validation to evaluate the performance of each 
hyperparameters combination by manually changing the value of hyperparameters. We use a greedy strategy based on the previous hyperparameters and find an appropriate hyperparameters combination of [4,0.0001,16,1500].

## Validation Error of Various Structures
|                                |       |        |       |       |         |          |          |
|--------------------------------|-------|--------|-------|-------|---------|----------|----------|
|**Net**   | **CinCECGTorso**    | **Coffee**  |  **CricketX**   |**FacesUCR** | **ItalyPower**  | **Mallat**  | **Averaged** |
|1	|0.5  |0.071	|0.241	|0.1 	  |0.045	|0.545	|0.25|
|2	|0.425|0	    |0.192	|0.035	|0.03	  |0.418  |0.183|
|3	|0.375|0	    |0.151	|0.03	  |0.03	  |0.055	|0.107|
|4	|0.4	|0	    |0.161	|0.03	  |0.03	  |0.055  |0.113|
|5	|0.45	|0	    |0.182	|0.035	|0.03	  |0.055  |0.125|
|6	|0.45	|0    	|0.2	  |0.075	|0.045	|0.073  |0.141|

## Averaged Validation Error of Different Hyperparameters Combination
|                                |       |        |       |       |
|--------------------------------|-------|--------|-------|-------|
|**Batch size**   | **Learning rate**    | **Reduction factor**  |  **Training epoch**   |**Averaged validation error** |
|4|			0.001|   16|	1500|   0.091|
|8|			0.001|   16|	1500|   0.095|
|16|		0.001|	 16|	1500|   0.107|
|32|		0.001|	 16|  1500|   0.12|
|4|		  0.01|    16|	1500|   0.131|
|4|		 	0.001|   16|	1500|   0.091|
|4|			0.0001|  16|	1500|   0.081|
|4|			0.0001|	    4|	1500|   0.097|
|4|			0.0001|	    8|	1500|   0.093|
|4|			0.0001|	   16|	1500|   0.081|
|4|			0.0001|	   32|	1500|   0.089|
|4|			0.0001|	   16|	1000|   0.092|
|4|			0.0001|	   16|	1500|   0.081|
|4|			0.0001|	   16|	2000|   0.081|

## Classification Results
We test our approach on 85 datasets from the UCR time series classification archive [[www.timeseriesclassification.com]](http://www.timeseriesclassification.com/). Since the label formats of different datasets is not uniformed, we rectify them by starting from 1. We select the following metrics to evaluate the performance of each method: Wins, Arithmetic Mean Ranking (AMR), Geometric Mean Ranking (GMR), and Mean Error (ME). Noted that, AMR follows the rules of Friedman Test.

|                                |       |        |       |       |         |          |         |       |       |
|--------------------------------|-------|--------|-------|-------|---------|----------|---------|-------|-------|  
|**Dataset**   | **BOSS**    | **Flat-COTE**  |  **Hive-COTE**   |**PROP** | **FCN**  | **ResNet**  | **SACNN** | **MCNN** | **MACNN**|
|Adiac|	0.251|	0.19|	0.185| 0.335|	0.143|	0.174|	0.187|	0.187|	0.176|
|ArrowHead|	0.125|	0.123|	0.112| 0.14|	0.12|	0.183|	0.166	|0.149|	0.137|
|Beef|	0.385|	0.236|	0.277| 0.468|	0.25|	0.233|	0.1|	0.1|	0.067|
|BeetleFly|	0.052	|0.079|	0.041| 0.178	|0.05|	0.2|	0.05|	0	|0|
|BirdChicken|	0.016|	0.059|	0.05| 0.152|	0.05|	0.1|	0|	0|	0|
|Car|	0.145|	0.101|	0.075| 0.201|  0.083|	0.067|	0.117|	0.1|	0.083|
|CBF| 0.002|	0.002|  0.001| 0.007|	0|	0.006|	0.004|	0|	0|
|ChlorineCon|	0.34|	0.264| 0.275	| 0.341|	0.157|	0.172|	0.153	|0.116	|0.112|
|CinCECGTorso	|0.1	| 0.017|	0.012| 0.054	|0.187|	0.229	|0.16	|0.149|	0.114|
|Coffee|  0.011|	0	| 0.002	| 0.011|	0	|0|	0	|0|	0|
|Computers|	0.198	|0.23|	0.181| 0.268|	0.152|	0.176|	0.18|	0.18|	0.168|
|CricketX|	0.236|	0.186	|0.17	|0.199|	0.185|	0.179	|0.254	|0.146|	0.138|
|CricketY|  0.251|	0.185	|0.163	|0.206|	0.208|	0.195	|0.231|	0.144	|0.131|
|CricketZ|	0.224	|0.173|	0.152|0.196|	0.187|	0.187|	0.215|	0.133	|0.121|
|DiatomSizeR|	0.061	|0.075|	0.058|0.054|	0.07|	0.069	|0.023|	0.023	|0.023|
|DistalPhalanxOutlineAgeGroup|	0.186|	0.179|	0.174|0.232|	0.165|	0.202|	0.252	|0.245|	0.232|
|DistalPhalanxOutlineCorrect|	0.185	|0.195|	0.175|0.232|	0.188|	0.18|	0.185	|0.228|	0.214|
|DistalPhalanxTW|	0.327|	0.307|	0.302|0.346|	0.21|	0.26	|0.317|	0.309	|0.302|
|Earthquakes|	0.254|	0.253	|0.253	|0.265|	0.199|	0.214|	0.252|	0.245|	0.245|
|ECG200	|0.11|	0.127|	0.118|0.119|	0.1|	0.13|	0.1	|0.09|	0.08|
|ECG5000	|0.06	|0.054|	0.053|0.061|	0.059|	0.069|	0.056|	0.051|	0.051|
|ECGFiveDays|	0.017|	0.014	|0.011	|0.153|	0.015	|0.045	|0.075|	0	|0|
|ElectricDevices|	0.201|	0.117	|0.11	|0.169	|0.277	|0.272|	0.332|	0.358|	0.304|
|FaceAll|	0.026	|0.01	|0.004	|0.024|	0.071|	0.166|	0.054|	0.131|	0.125|
|FaceFour|	0.004|	0.15	|0.051	|0.121|	0.068|	0.068	|0.091|	0.034|	0.034|
|FacesUCR	|0.049|	0.033|	0.016|	0.052|	0.052|	0.042	|0.047|	0.021|	0.02|
|FiftyWords|	0.298|	0.199	|0.193	|0.179|	0.321|	0.273|	0.253|	0.141	|0.13|
|Fish|	0.031|	0.038|	0.024|0.087	|0.029|	0.011	|0.017|	0.006|	0.006|
|FordA|	0.081	|0.045|	0.04|0.249|	0.094|	0.072|	0.063	|0.047	|0.045|
|FordB|	0.089|	0.071|	0.073|0.243	|0.117|	0.1|	0.194|	0.148|	0.126|
|GunPoint|	0.006	|0.008|0.003|	0.026|	0	|0.007|	0|	0|	0|
|Ham|	0.164	|0.195|	0.159|0.237|	0.238|	0.219	|0.286	|0.171|	0.171|
|HandOutlines|	0.097|	0.106	|0.088	|0.12	|0.224|	0.139|	0.076|	0.051|	0.049|
|Haptics|	0.541	|0.483|	0.47|0.549	|0.449	|0.494|	0.545|	0.458|	0.458|
|Herring|	0.395|	0.368	|0.366	|0.434|	0.297|	0.406	|0.328|	0.328|	0.312|
|InlineSkate|	0.497|	0.474|	0.474|0.524	|0.589|	0.635|	0.533|	0.504|	0.504|
|InsectWingbeatSound|	0.49|	0.361|	0.365|0.419|	0.598|	0.469	|0.547|	0.368	|0.353|
|ItalyPowerDemand|	0.134	|0.03| 0.032|	0.049|	0.03|	0.04	|0.028	|0.028|	0.028|
|LargeKitchenAppliances|	0.163|	0.1|	0.077|0.184|	0.104|	0.107|	0.093|	0.08|0.08|
|Lightning2	|0.19	|0.215|	0.203|0.165	|0.197|	0.246|	0.213|	0.197|	0.18|
|Lightning7|	0.334|	0.201|	0.189|0.237|	0.137	|0.164|	0.192|	0.151|	0.137|
|Mallat|	0.051	|0.026|	0.025|0.039	|0.02|	0.021|	0.025|	0.024|	0.02|
|Meat	|0.02|	0.019|	0.013|0.022|	0.033|	0|	0.017	|0.017|	0|
|MedicalImages|	0.285|	0.215|	0.185|	0.24|	0.208	|0.228|	0.234|	0.238|	0.217|
|MiddlePhalanxOutlineAgeGroup|	0.334|	0.278|	0.295|0.391	|0.232|	0.24	|0.416	|0.409	|0.383|
|MiddlePhalanxOutlineCorrect|	0.192|	0.199|	0.191|0.218|	0.205|	0.207|	0.168|	0.179|	0.162|
|MiddlePhalanxTW	|0.463|	0.413|	0.429|0.475|	0.388	|0.393	|0.409|	0.468	|0.409|
|MoteStrain	|0.154	|0.098|	0.053|0.125|	0.05|	0.105	|0.082|	0.082|	0.082|
|NonInvThorax1	|0.159	|0.071|	0.068|0.151	|0.039|	0.052|	0.053|	0.051|	0.051|
|NonInvThorax2	|0.096|	0.054	|0.048	|0.086	|0.045|	0.049	|0.054|	0.045|	0.045|
|OliveOil|	0.13|	0.099	|0.102	|0.121|	0.167	|0.133	|0.167|	0.1	|0.1|
|OSULeaf|	0.033	|0.051|	0.03|0.188|	0.012|	0.021|	0.029|	0.021|	0.021|
|PhalangesOutlinesCorrect	|0.179	|0.217|	0.179|0.22|	0.174|	0.175|	0.176|	0.17	|0.167|
|Phoneme	|0.744|	0.638	|	0.615	|0.701|	0.655|	0.676|	0.664	|0.678|	0.66|
|Plane|	0.002	|0	|0	|0	|0|	0	|0	|0|	0|
|ProximalPhalanxOutlineAgeGroup	|0.181|	0.152|	0.152|0.195	|0.151|	0.151	|0.151|	0.151	|0.146|
|ProximalPhalanxOutlineCorrect	|0.133	|0.129|	0.124|0.161|	0.1	|0.082|	0.079	|0.079|	0.076|
|ProximalPhalanxTW	|0.227	|0.185|	0.188|0.241	|0.19|	0.193|	0.224|	0.224	|0.208|
|RefrigerationDevices|	0.215|	0.258	|0.199	|0.324|	0.467|	0.472|	0.429|	0.424|	0.411|
|ScreenType|	0.414	|0.349	|0.289	|0.446|	0.333	|0.293|	0.365	|0.371|	0.352|
|ShapeletSim	|0|	0.036	|0.009	|0.173	|0.133|	0	|0.011	|0	|0|
|ShapesAll|	0.091	|0.089	|0.074	|0.114	|0.102	|0.088|	0.1|	0.065|	0.06|
|SmallKitchenAppliances	|0.25|	0.212|	0.163|0.297	|0.197|	0.203	|0.219|	0.205|	0.192|
|SonyAIBORobot|	0.103	|0.101| 0.113|0.206	|0.032|	0.015	|0.017|	0.017|	0.015|
|SonyAIBORobotII|	0.112	|0.04	|0.055	|0.13|	0.038|	0.038|	0.024|	0.04|	0.038|
|StarLightCurves|	0.022	|0.02	|0.019	|0.059|	0.033	|0.025|	0.026	|0.024|	0.022|
|Strawberry	|0.03	|0.037	|0.03	|0.041	|0.031|	0.042	|0.027|	0.024	|0.024|
|SwedishLeaf|	0.082	|0.033	|0.031	|0.084	|0.034|	0.042|	0.037	|0.037	|0.037|
|Symbols	|0.039	|0.047	|0.034	|0.043|	0.038|	0.128|	0.021|	0.021|	0.02|
|SyntheticControl	|0.032|	0.001	|0	|0.006	|0.01	|0	|0|	0	|0|
|ToeSegmentation1	|0.071	|0.066|	0.045|0.212|	0.031|	0.035|	0.026	|0.026|	0.026|
|ToeSegmentation2	|0.04	|0.049|	0.034|0.093	|0.085|	0.138|	0.069	|0.054|	0.054|
|Trace	|0	|0|	0|0.004	|0	|0	|0	|0	|0|
|TwoLeadECG|	0.016|	0.018	|0.007	|0.042|	0	|0	|0.001|	0	|0|
|TwoPatterns	|0.009	|0|	0|0	|0.103|	0	|0.003|	0	|0|
|UWaveAll|	0.056	|0.035	|0.03	|0.032	|0.174|	0.132|	0.128	0.054|	0.04|
|UWaveX	|0.247	|0.17	|0.162	|0.195	|0.246|	0.213|	0.204|	0.169	|0.16|
|UWaveY	|0.339	|0.234|	0.225|0.27	|0.275|	0.332|	0.3|	0.229|	0.219|
|UWaveZ	|0.305|	0.241|	0.222|0.274	|0.271|	0.245|	0.246|	0.223|	0.212|
|Wafer|	0.001	|0.001|	0|0.003|	0.003|	0.003|	0	|0	|0|
|Wine|	0.088|	0.097|	0.088|0.113	|0.111|	0.204|	0.167|	0.148|	0.13|
|WordSynonyms|	0.341	|0.252|	0.252|0.222	|0.42|	0.368|	0.394	|0.255|	0.234|
|Worms	|0.265	|0.275	|0.266	|0.356	|0.331	|0.381	|0.13|	0.156	|0.143|
|WormsTwoClass|	0.19	|0.215|	0.216|0.283	|0.271	|0.265|	0.156|	0.182	|0.13|
|Yoga|	0.09	|0.102	|0.083	|0.115	|0.155|	0.142|	0.104	|0.082	|0.08|
|Wins|	4	|8|	25|	4|	21|	10	|12	|20|	44|
|AMR	|6.376	|5.047|3.624|	7.418|	5|	5.582|	5.341|3.859	|2.753|
|GMR	|5.864|	4.529	|2.977	|6.914|	4.061|4.964	|4.822|	3.42|	2.293|
|ME|	0.1666	|0.1421	|0.1308	|0.1882|	0.156	|0.1615|	0.1544|	0.136|	0.1271|


## Averaged Classification Results
Since the initial weights of deep learning based models may result in the bias [[Fawaz et al.]](https://arxiv.org/abs/1809.04356), we take the same strategy to run the experiments 10 times and compare the averaged error rate with the top two deep learning models according to the study of Fawaz et al. Noted that, the values in the parentheses refer to the standard deviation, and we add one more evaluation metric named as Mean Standard Deviation (MSD) to measure the stability of the model.

|                                |       |        |       |       |         |
|--------------------------------|-------|--------|-------|-------|---------|  
|**Dataset**   | **FCN**    | **ResNet** | **SACNN** | **MCNN** | **MACNN**|
|Adiac	|0.156(0.007)	|0.171(0.006)|	0.202(0.011)|	0.197(0.007)|	0.188(0.011)|
|ArrowHead|	0.157(0.015)|	0.155(0.012)|	0.186(0.024)|	0.154(0.008)|	0.145(0.007)|
|Beef|	0.303(0.04)|	0.247(0.042)|	0.137(0.046)|	0.117(0.022)|	0.093(0.025)|
|BeetleFly|	0.14(0.097)	|0.15(0.024)	|0.075(0.046)|	0.01(0.02)|	0.005(0.015)|
|BirdChicken|	0.045(0.037)|	0.115(0.053)|	0.03(0.04)|	0.02(0.033)|	0.01(0.03)|
|Car|	0.095(0.014)|	0.075(0.014)|	0.139(0.024)|	0.108(0.009)|	0.09(0.008)|
|CBF|	0.006(0.001)|	0.005(0.003)|	0.01(0.006)	|0.001(0.001)|	0.001(0.001)|
|ChlorineCon|	0.186(0.009)|	0.156(0.01)|	0.161(0.005)|	0.12(0.003)|	0.118(0.004)|
|CinCECGTorso|	0.176(0.012)|	0.174(0.024)|	0.172(0.012)|	0.159(0.013)|	0.123(0.011)|
|Coffee|	0(0)|	0(0)|	0(0)|	0(0)|	0(0)|
|Computers|	0.178(0.01)|	0.185(0.012)|	0.195(0.019)|	0.193(0.013)|	0.186(0.017)|
|CricketX|	0.208(0.007)|	0.209(0.006)|	0.265(0.012)|	0.159(0.014)|	0.146(0.008)|
|CricketY|	0.213(0.012)|	0.197(0.008)|	0.25(0.024)|	0.155(0.013)|	0.137(0.007)|
|CricketZ|	0.189(0.01)|	0.188(0.014)|	0.225(0.013)|	0.143(0.012)|	0.13(0.011)|
|DiatomSizeR|	0.687(0.036)|	0.699(0.002)|	0.039(0.022)|	0.032(0.011)|	0.03(0.011)|
|DistalPhalanxOutlineAgeGroup|	0.29(0.013)|	0.283(0.013)|	0.269(0.023)|	0.252(0.011)|	0.238(0.013)|
|DistalPhalanxOutlineCorrect|	0.24(0.015)|	0.229(0.01)|	0.208(0.028)|	0.235(0.009)|	0.225(0.012)|
|DistalPhalanxTW|	0.31(0.021)|	0.335(0.016)|	0.327(0.012)|	0.321(0.015)|	0.318(0.011)|
|Earthquakes|	0.273(0.017)|	0.288(0.02)|	0.263(0.012)|	0.253(0.011)|	0.252(0.007)|
|ECG200|	0.111(0.01)|	0.126(0.019)|	0.102(0.004)|	0.095(0.005)|	0.085(0.005)|
|ECG5000|	0.06(0.001)|	0.066(0.002)|	0.061(0.004)|	0.055(0.004)|	0.054(0.003)|
|ECGFiveDays|	0.013(0.003)|	0.025(0.019)|	0.087(0.019)|	0.006(0.007)|	0.003(0.006)|
|ElectricDevices|	0.298(0.012)|	0.271(0.009)|	0.354(0.016)|	0.363(0.01)|	0.309(0.009)|
|FaceAll|	0.055(0.009)|	0.161(0.02)|	0.067(0.017)|	0.142(0.013)|	0.131(0.009)|
|FaceFour|	0.072(0.009)|	0.045(0)|	0.113(0.026)|	0.044(0.01)|	0.044(0.009)|
|FacesUCR|	0.054(0.002)|	0.045(0.004)|	0.051(0.003)|	0.026(0.005)|	0.024(0.005)|
|FiftyWords|	0.373(0.061)|	0.26(0.015)|	0.265(0.014)|	0.153(0.01)|	0.138(0.01)|
|Fish|	0.042(0.006)|	0.021(0.008)|	0.023(0.006)|	0.012(0.01)|	0.011(0.011)|
|FordA|	0.096(0.002)|	0.08(0.004)|	0.068(0.009)|	0.052(0.007)|	0.05(0.008)|
|FordB|	0.122(0.006)|	0.087(0.003)|	0.206(0.013)|	0.15(0.004)|	0.132(0.005)|
|GunPoint|	0(0)|	0.009(0.007)|	0.003(0.003)|	0.002(0.003)|	0.002(0.003)|
|Ham|	0.282(0.014)|	0.243(0.027)|	0.292(0.014)|	0.178(0.007)|	0.178(0.007)|
|HandOutlines|	0.194(0.079)|	0.089(0.014)|	0.086(0.008)|	0.068(0.014)|	0.062(0.014)|
|Haptics|	0.52(0.024)|	0.481(0.012)|	0.565(0.021)|	0.468(0.011)|	0.468(0.011)|
|Herring|	0.392(0.077)|	0.381(0.038)|	0.366(0.036)|	0.344(0.017)|	0.325(0.014)|
|InlineSkate|	0.661(0.008)|	0.627(0.009)|	0.554(0.022)|	0.517(0.016)|	0.517(0.012)|
|InsectWingbeatSound|	0.607(0.006)|	0.493(0.009)|	0.561(0.012)|	0.373(0.007)|	0.357(0.005)|
|ItalyPower|	0.039(0.003)|	0.037(0.004)|	0.033(0.004)|	0.033(0.003)|	0.032(0.004)|
|LargeKitchenAppliances|	0.098(0.004)|	0.1(0.005)|	0.098(0.004)|	0.087(0.007)|	0.085(0.004)|
|Lightning2|	0.261(0.014)|	0.23(0.017)|	0.241(0.038)|	0.218(0.031)|	0.197(0.018)|
|Lightning7|	0.173(0.023)|	0.155(0.02)|	0.222(0.032)|	0.177(0.021)|	0.159(0.016)|
|Mallat|	0.033(0.009)|	0.028(0.003)|	0.031(0.007)|	0.029(0.008)|	0.025(0.005)|
|Meat|	0.147(0.069)|	0.032(0.025)|	0.047(0.033)|	0.037(0.028)|	0.022(0.026)|
|MedicalImages|	0.221(0.004)|	0.23(0.007)|	0.248(0.017)|	0.244(0.016)|	0.226(0.012)|
|MiddlePhalanxOutlineAgeGroup|	0.447(0.018)|	0.431(0.021)|	0.433(0.018)|	0.419(0.021)|	0.391(0.012)|
|MiddlePhalanxOutlineCorrect|	0.199(0.01)|	0.191(0.012)|	0.181(0.011)|	0.187(0.008)|	0.171(0.01)|
|MiddlePhalanxTW|	0.488(0.018)|	0.516(0.02)|	0.432(0.029)|	0.482(0.016)|	0.419(0.005)|
|MoteStrain|	0.063(0.005)|	0.072(0.005)|	0.092(0.009)|	0.091(0.007)|	0.09(0.007)|
|NonInvThorax1|	0.044(0.003)|	0.055(0.003)|	0.057(0.004)|	0.055(0.003)|	0.055(0.003)|
|NonInvThorax2|	0.047(0.003)|	0.054(0.003)|	0.058(0.005)|	0.049(0.003)|	0.047(0.003)|
|OliveOil|	0.277(0.166)|	0.17(0.085)|	0.217(0.128)|	0.153(0.069)|	0.15(0.065)|
|OSULeaf|	0.023(0.009)|	0.021(0.008)|	0.038(0.009)|	0.03(0.008)|	0.029(0.008)|
|PhalangesOutlinesCorrect|	0.18(0.005)|	0.161(0.012)|	0.185(0.009)|	0.176(0.008)|	0.174(0.005)|
|Phoneme|	0.675(0.005)|	0.666(0.007)|	0.673(0.01)|	0.689(0.011)|	0.664(0.004)|
|Plane|	0(0)|	0(0)|	0(0)|	0(0)|	0(0)|
|ProximalPhalanxOutlineAgeGroup|	0.169(0.013)|	0.147(0.008)|	0.162(0.008)|	0.16(0.006)|	0.153(0.006)|
|ProximalPhalanxOutlineCorrect|	0.097(0.007)|	0.079(0.006)|	0.095(0.008)|	0.086(0.007)|	0.084(0.006)|
|ProximalPhalanxTW|	0.233(0.009)|	0.22(0.017)|	0.237(0.014)|	0.235(0.014)|	0.213(0.011)|
|RefrigerationDevices|	0.492(0.01)|	0.475(0.025)|	0.448(0.022)|	0.437(0.02)|	0.421(0.015)|
|ScreenType|	0.375(0.016)|	0.378(0.014)|	0.389(0.018)|	0.4(0.018)|	0.365(0.016)|
|ShapeletSim|	0.276(0.056)|	0.221(0.15)|	0.024(0.015)|	0.006(0.008)|	0.006(0.009)|
|ShapesAll|	0.105(0.004)|	0.079(0.004)|	0.103(0.005)|	0.074(0.017)|	0.067(0.011)|
|SmallKitchenAppliances|	0.217(0.013)|	0.214(0.008)|	0.227(0.01)|	0.216(0.016)|	0.204(0.011)|
|SonyAIBORobot|	0.04(0.007)|	0.042(0.013)|	0.027(0.008)|	0.024(0.01)|	0.021(0.007)|
|SonyAIBORobotII|	0.021(0.005)|	0.022(0.005)|	0.026(0.002)|	0.044(0.004)|	0.041(0.003)|
|StarLightCurves|	0.039(0.009)|	0.028(0.003)|	0.031(0.006)|	0.027(0.002)|	0.024(0.002)|
|Strawberry|	0.028(0.003)|	0.019(0.004)|	0.03(0.003)|	0.028(0.006)|	0.027(0.004)|
|SwedishLeaf|	0.031(0.005)|	0.044(0.004)|	0.041(0.004)|	0.039(0.002)|	0.039(0.001)|
|Symbols|	0.045(0.01)|	0.094(0.023)|	0.035(0.021)|	0.027(0.009)|	0.025(0.009)|
|SyntheticControl|	0.015(0.003)|	0.002(0.002)|	0.001(0.001)|	0.001(0.001)|	0.001(0.001)|
|ToeSegmentation1|	0.039(0.005)|	0.037(0.006)|	0.042(0.006)|	0.036(0.008)|	0.034(0.006)|
|ToeSegmentation2|	0.12(0.033)|	0.094(0.017)|	0.096(0.024)|	0.061(0.006)|	0.061(0.005)|
|Trace|	0(0)|	0(0)|	0(0)|	0(0)|	0(0)|
|TwoLeadECG|	0(0)|	0(0)|	0.001(0.001)|	0.001(0.001)|	0.001(0.001)|
|TwoPatterns|	0.129(0.003)|	0(0)|	0.013(0.007)|	0(0)|	0(0)|
|UWaveAll|	0.183(0.003)|	0.14(0.004)|	0.134(0.012)|	0.059(0.012)|	0.044(0.004)|
|UWaveX|	0.246(0.004)|	0.22(0.004)|	0.214(0.012)|	0.179(0.011)|	0.165(0.006)|
|UWaveY|	0.361(0.006)|	0.33(0.007)|	0.307(0.005)|	0.234(0.004)|	0.221(0.003)|
|UWaveZ|	0.274(0.005)|	0.25(0.004)|	0.255(0.006)|	0.231(0.007)|	0.216(0.004)|
|Wafer|	0.003(0)|	0.001(0.001)|	0.001(0.001)|	0.001(0.001)|	0.001(0.001)|
|Wine|	0.413(0.083)|	0.256(0.085)|	0.228(0.098)|	0.194(0.061)|	0.161(0.058)|
|WordSynonyms|	0.436(0.012)|	0.378(0.015)|	0.407(0.012)|	0.268(0.011)|	0.242(0.009)|
|Worms|	0.235(0.022)|	0.209(0.025)|	0.142(0.018)|	0.172(0.018)|	0.151(0.012)|
|WormsTwoClass|	0.274(0.027)|	0.253(0.033)|	0.164(0.019)|	0.196(0.019)|	0.141(0.014)|
|Yoga|	0.161(0.007)|	0.13(0.009)|	0.116(0.007)|	0.086(0.005)|	0.084(0.004)|
|Wins|	15|	15|	7|	13|	63|
|AMR|	3.869|	3.256|	3.732|	2.589|	1.554|
|GMR|	3.448|	2.939|  3.513|	2.425|	1.391|
|ME|	0.1915|	0.1751|	0.1678|	0.1454|	0.135|
|MSD|	0.0171|	0.0148|	0.0161|	0.0113|	0.0094|


